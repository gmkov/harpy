[[{"i":"#","p":["Using Harpy to process your haplotagged data"]},{"l":"Home","p":["Harpy is a haplotagging data processing pipeline for Linux-based systems. It uses all the magic of Snakemake under the hood to handle the worklfow decision-making, but as a user, you just interact with it like a normal command-line"]},{"i":"what-is-haplotagging","l":"What is haplotagging?","p":["Linked-read sequencing exists to combine the throughput and accuracy of short-read sequencing with the long range haplotype information of long-read sequencing. Haplotagging is an implementation of linked-read sequencing developed by"]},{"l":"Harpy Modules","p":["Harpy is modular, meaning you can use different parts of it independent from each other. Need to only align reads? Great! Only want to call variants? Awesome! All modules are called by"]},{"l":"Using Harpy","p":["You can call harpy without any arguments (or with --help) to print the docstring to your terminal. You can likewise call any of the modules without arguments or with --help to see their usage (e.g."]}],[{"l":"Install HARPY"},{"l":"Clone the repository","p":["Until this pipeline gets completed and hosted on Bioconda, it will be available by cloning/downloading the repository."]},{"l":"Install the dependencies","p":["The dependencies can be installed into a conda environment using the provided harpyenv.yaml:"]},{"l":"Activate the environment","p":["The environment with all the preinstalled dependencies can be activated with:"]}],[{"l":"Before you start"},{"l":"Required files and formats","p":["Before you start using Harpy for your haplotagging data processing, you will need to make sure you have a few things on hand for things to go smoothly. At the minimum, you will need:"]},{"l":"Adding additional Snakamake parameters","p":["Harpy relies on Snakemake under the hood to handle file and job dependencies. Most of these details have been abstracted away from the end-user, but every module of Harpy (except"]},{"l":"Reserved arguments","p":["Harpy calls Snakemake using specific arguments, meaning you cannot append these again to the internal command line call. Well, you can, but Snakemake will error and exit. Everything else"]},{"l":"Use cases","p":["You likely wont need to invoke --snakemake very often, if ever. However, here are common use cases for this parameter."]}],[{"i":"#","p":["Generate extra files for analysis with Harpy"]},{"l":"Generate Extra Files","p":["Some parts of Harpy (variant calling, imputation) want or need extra files. You can create various files necessary for different modules using the harpy extra module:"]},{"l":"Running Options"},{"l":"popgroup"},{"l":"stitch-params"},{"l":"hpc"}],[{"i":"#","p":["Quality trim haplotagged sequences with Harpy"]},{"l":"Quality Trim Sequences","p":["Raw sequences are not suitable for downstream analyses. They have sequencing adapters, index sequences, regions of poor quality, etc. The first step of any genetic sequence analyses is to remove these adapters and trim poor quality data. You can remove adapters"]},{"l":"Running Options"},{"l":"Trimming Workflow"}],[{"i":"#","p":["Align haplotagged sequences to a reference genome with Harpy"]},{"l":"Mapping Reads onto a genome","p":["Once sequences have been trimmed and passed through other QC filters, they will need to be aligned to a reference genome. This module within Harpy expects filtered reads as input,"]},{"l":"Running Options"},{"l":"Quality filtering","p":["Every alignment in a BAM file has an associated mapping quality ( MQ) score that informs you of the likelihood that the alignment is accurate. This score can range from 0-40, where higher numbers mean the alignment is more"]},{"l":"EMA workflow"},{"l":"BWA workflow"}],[{"i":"#","p":["Call variants on alignments generated from haplotagged sequences with Harpy"]},{"l":"Calling Variants","p":["After reads have been aligned, e.g. with harpy align, you can use those alignment files(.bam) to call variants in your data. Harpy can call variants using bcftools mpileup, which calls SNPs and indels primarily, or with"]},{"l":"Running Options"},{"l":"sample grouping file","p":["This file is entirely optional and useful if you want variant calling to happen on a per-population level."]},{"l":"mpileup workflow"},{"l":"LEVIATHAN workflow"}],[{"i":"#","p":["Impute genotypes for haplotagged data with Harpy"]},{"l":"Impute Genotypes using Sequences","p":["After variants have been called, you may want to impute missing genotypes to get the most from your data. Harpy uses STITCH to impute genotypes, a haplotype-based method that is linked-read aware. Imputing genotypes requires a variant call file"]},{"l":"Running Options"},{"l":"Parameter file","p":["Typically, one runs STITCH multiple times, exploring how results vary with different model parameters. The solution Harpy uses for this is to have the user provide a tab-delimited dataframe file where the columns are the 5 STITCH model"]},{"l":"model"},{"l":"useBX"},{"l":"k"},{"l":"s"},{"l":"nGen"},{"l":"Imputation Workflow"}],[{"i":"#","p":["Phase haplotypes for haplotagged data with Harpy"]},{"l":"Phasing Haplotypes","p":["You may want to phase your genotypes into haplotypes, as haplotypes tend to be more informative than unphased genotypes (higher polymorphism, captures relationship between genotypes). Phasing"]},{"l":"Running Options","p":["The molecule distance is and pruning thresholds are considered the most impactful parameters for running HapCut2, therefore they are directly configurable from the command. The molecule distance"]},{"l":"Phasing Workflow"}],[{"l":"Software used in HARPY","p":["HARPY is the sum of its parts, and out of tremendous respect for the developers involved in the included software, we would like to highlight the tools directly involved in HARPY's many moving pieces."]}]]