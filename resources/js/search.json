[[{"l":"Home","p":["Harpy is a haplotagging data processing pipeline for Linux-based systems. It uses all the magic of Snakemake under the hood to handle the worklfow decision-making, but as a user, you just interact with it like a normal command-line"]},{"l":"Modules","p":["Harpy is modular, meaning you can use different parts of it independent from each other. Need to only align reads? Great! Only want to call variants? Awesome! All modules are called by"]},{"l":"Using Harpy","p":["You can call harpy without any arguments (or with --help) to print the docstring to your terminal. You can likewise call any of the modules with --help(e.g. harpy align --help) to see their usage."]}],[{"l":"Install HARPY","p":["Until this pipeline gets completed and hosted on Bioconda, it will be available by cloning/downloading the repository. The dependencies can be installed into a conda environment using the provided"]}],[{"l":"Generate Extra Files","p":["Some parts of Harpy (variant calling, imputation) want or need extra files. You can create various files necessary for different modules using the harpy extra module:"]},{"l":"Running Options"},{"l":"popgroup"},{"l":"stitch-params"},{"l":"hpc"}],[{"l":"Quality Trimming Sequence Data","p":["You can remove adapters and quality trim sequences using:"]},{"l":"Running Options"},{"l":"Fastp Workflow","p":["Fastp is an ultra-fast all-in-one adapter remover, deduplicator, and quality trimmer. Harpy uses it to remove adapters, low-quality bases, and trim sequences down to a particular"]}],[{"l":"Mapping Reads onto a Reference Genome","p":["You can map reads onto genome assemblies with Harpy by calling the align module:"]},{"l":"Running Options"},{"l":"Workflows"},{"l":"EMA","p":["Since EMA does extra things to account for barcode information, the EMA workflow is a bit more complicated under the hood. Reads with barcodes are aligned using EMA and reads without valid barcodes are separately mapped using BWA before merging all the alignments together again."]},{"l":"BWA","p":["The BWA MEM workflow is substantially simpler than the EMA workflow and maps all reads against the reference genome, no muss no fuss. Duplicates are marked at the end using sambamba"]},{"i":"why-ema","l":"Why EMA?","p":["The original haplotag manuscript uses BWA to map reads, but the authors have since then recommended the use of EMA (EMerald Aligner) for most applications."]}],[{"l":"Calling Variants","p":["You can call variants with Harpy by calling the variants module:"]},{"l":"Running Options"},{"l":"sample grouping file","p":["This file is entirely optional and useful if you want variant calling to happen on a per-population level."]},{"l":"Workflows"},{"l":"bcftools mpileup","p":["The mpileup and call modules from bcftools(formerly samtools) are used to call variants from alignments. This is a tried-and-true method and one of methods featured in other variant"]},{"l":"Leviathan","p":["Leviathan is an alternative variant caller that uses linked read barcode information to call structural variants (indels, inversions, etc.). Harpy first uses LRez to index the barcodes"]},{"l":"Individual-level variant calling","p":["Leviathan is intended to call structural variants on individual samples. Without using a population grouping file (--populations), variants will be called per-sample. Due to the nature of Structural Variant (SV) VCF files, there isn't an entirely fool-proof way"]},{"l":"Population-level variant calling","p":["Some internal preliminary work revealed better SV calling when samples are grouped by population. With the inclusion of a population grouping file via --populations, Harpy will merge the bam files from for all samples within a population and call SV's on these"]}],[{"l":"Impute Genotypes using Sequences","p":["You can impute genotypes with Harpy by calling the impute module:"]},{"l":"Running Options"},{"l":"Parameter file","p":["Typically, one runs STITCH multiple times, exploring how results vary with different model parameters. The solution Harpy uses for this is to have the user provide a tab-delimited dataframe file where the columns are the 5 STITCH model"]},{"l":"example"},{"l":"model"},{"l":"useBX"},{"l":"k"},{"l":"s"},{"l":"nGen"},{"l":"STITCH Workflow","p":["STITCH is a genotype imputation software developed for use in the R programming language. It has quite a few model parameters that can be tweaked, but HARPY only focuses on a small handful that have the largest impact on the quality of the results. Imputation is"]}],[{"l":"Phasing Haplotypes","p":["You can phase genotypes into haplotypes using:"]},{"l":"Running Options","p":["The molecule distance is and pruning thresholds are considered the most impactful parameters for running HapCut2, therefore they are directly configurable from the command. The molecule distance"]},{"l":"HapCut2 Workflow","p":["Phasing is performed using HapCut2. Most of the tasks cannot be parallelized, but HapCut2 operates on a per-sample basis, so the workflow is parallelized across all of your samples to speed things along."]}],[{"l":"Adding additional Snakamake parameters","p":["Harpy relies on Snakemake under the hood to handle file and job dependencies. Most of these details have been abstracted away from the end-user, but every module of Harpy (except"]},{"l":"Use cases","p":["You likely wont need to invoke --snakemake very often, if ever. That being said, here are what might be the most common use cases for this parameter."]},{"l":"Dry run"},{"i":"--dry-run","l":"--dry-run","p":["This is a directive in which Snakemake will build the DAG and \"pretend\" to run the Harpy workflow. Useful for knowing what you're getting yourself into ahead of time. It's also useful for debugging during development."]},{"l":"Rerun an incomplete workflow"},{"i":"--rerun-incomplete","l":"--rerun-incomplete","p":["There will be plenty of reasons that Harpy/Snakemake might end prematurely, like corrupt files, system errors, insufficient resources, etc. When this happens, Snakemake has a save-state in the"]}],[{"l":"Software used in HARPY","p":["HARPY is the sum of its parts, and out of tremendous respect for the developers involved in the included software, we would like to highlight the tools directly involved in HARPY's many moving pieces."]}]]