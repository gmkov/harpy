[[{"i":"#","p":["Using Harpy to process your haplotagged data"]},{"l":"Home","p":["Harpy is a haplotagging data processing pipeline for Linux-based systems. It uses all the magic of Snakemake under the hood to handle the worklfow decision-making, but as a user, you just interact with it like a normal command-line"]},{"i":"what-is-haplotagging","l":"What is haplotagging?","p":["Linked-read sequencing exists to combine the throughput and accuracy of short-read sequencing with the long range haplotype information of long-read sequencing. Haplotagging is an implementation of linked-read sequencing developed by"]},{"l":"Harpy Modules","p":["Harpy is modular, meaning you can use different parts of it independent from each other. Need to only align reads? Great! Only want to call variants? Awesome! All modules are called by"]},{"l":"Using Harpy","p":["You can call harpy without any arguments (or with --help) to print the docstring to your terminal. You can likewise call any of the modules without arguments or with --help to see their usage (e.g."]}],[{"l":"Install HARPY","p":["Harpy is now hosted on Bioconda! That means to install it, you just need to have conda(or mamba) on your system and install it with a simple command. You can install Harpy into an existing environment or create a new one for it (recommended)."]}],[{"l":"Haplotag data format"},{"l":"Barcodes","p":["While barcodes are actually combinatorial bases, in the read headers they are represented with the format AxxCxxBxxDxx, where each barcode segment is denoted as Axx(or Bxx, etc.)."]},{"l":"where the barcodes go","p":["Chromium 10X linked-reads have a particular format where the barcode is the leading 16 bases of the read. However, haplotagging data does not use that format, nor do the tools implemented in Harpy work correctly with it."]},{"l":"Read headers","p":["Like mentioned immediately above this sentence, the haplotag barcode is expected to be stored in the BX:Z: tag in the read header. This information is retained through the various Harpy"]},{"l":"Read length","p":["Reads must be at least 30 base pairs in length for alignment. The trim module removes reads <50bp."]},{"l":"Compression","p":["Harpy expects the input sequences to be in gzipped/bgzipped format, therefore the file names should end in .gz. This is a hard requirement and it's good practice to compress your reads"]},{"l":"Naming conventions","p":["Input sequences will have the format {samplename}.{extension}. To make sure there are no hiccups, this section details valid naming conventions for both the {samplename} and {extension}"]},{"l":"sample names","p":["Sample names must not have any unusual special characters in them. Keep to common conventions, such as underscore (_) or hyphen (-) separators. Examples:"]},{"l":"file extensions","p":["There are a handful of \"accepted\" naming schemes for fastq file extensions, but Harpy only accepts a limited number of them, shown below. The fastq files must be consistent with regards to the extensions and read-pair naming styles."]}],[{"i":"#","p":["Generate extra files for analysis with Harpy"]},{"l":"Generate Extra Files","p":["Some parts of Harpy (variant calling, imputation) want or need extra files. You can create various files necessary for different modules using the harpy extra module:"]},{"l":"Running Options"},{"l":"popgroup"},{"l":"stitch-params"},{"l":"hpc"}],[{"i":"#","p":["Quality trim haplotagged sequences with Harpy"]},{"l":"Quality Trim Sequences","p":["Raw sequences are not suitable for downstream analyses. They have sequencing adapters, index sequences, regions of poor quality, etc. The first step of any genetic sequence analyses is to remove these adapters and trim poor quality data. You can remove adapters"]},{"l":"Running Options"},{"l":"Trimming Workflow"}],[{"i":"#","p":["Align haplotagged sequences to a reference genome with Harpy"]},{"l":"Mapping Reads onto a genome","p":["Once sequences have been trimmed and passed through other QC filters, they will need to be aligned to a reference genome. This module within Harpy expects filtered reads as input,"]},{"l":"Running Options"},{"l":"Quality filtering","p":["The --quality argument filters out alignments below a given MQ threshold. The default, 30, keeps alignments that are at least 99.9% likely correctly mapped. Set this value to 1"]},{"l":"BWA workflow"},{"l":"EMA workflow"}],[{"i":"#","p":["Call variants on alignments generated from haplotagged sequences with Harpy"]},{"l":"Calling Variants","p":["After reads have been aligned, e.g. with harpy align, you can use those alignment files(.bam) to call variants in your data. Harpy can call variants using bcftools mpileup, which calls SNPs and indels primarily, or with"]},{"l":"Running Options"},{"l":"sample grouping file","p":["This file is entirely optional and useful if you want variant calling to happen on a per-population level."]},{"l":"mpileup workflow"},{"l":"NAIBR workflow"},{"l":"LEVIATHAN workflow"}],[{"i":"#","p":["Impute genotypes for haplotagged data with Harpy"]},{"l":"Impute Genotypes using Sequences","p":["After variants have been called, you may want to impute missing genotypes to get the most from your data. Harpy uses STITCH to impute genotypes, a haplotype-based method that is linked-read aware. Imputing genotypes requires a variant call file"]},{"l":"Running Options"},{"l":"Parameter file","p":["Typically, one runs STITCH multiple times, exploring how results vary with different model parameters (explained in next section). The solution Harpy uses for this is to have the user"]},{"l":"STITCH Parameters"},{"l":"Imputation Workflow"}],[{"i":"#","p":["Phase haplotypes for haplotagged data with Harpy"]},{"l":"Phasing Haplotypes","p":["You may want to phase your genotypes into haplotypes, as haplotypes tend to be more informative than unphased genotypes (higher polymorphism, captures relationship between genotypes). Phasing"]},{"l":"Running Options","p":["The molecule distance is and pruning thresholds are considered the most impactful parameters for running HapCut2, therefore they are directly configurable from the command. The molecule distance"]},{"l":"Phasing Workflow"}],[{"l":"Adding Snakamake parameters","p":["Harpy relies on Snakemake under the hood to handle file and job dependencies. Most of these details have been abstracted away from the end-user, but every module of Harpy (except"]},{"l":"Common use cases","p":["You likely wont need to invoke --snakemake very often, if ever. However, here are common use cases for this parameter."]}],[{"l":"Software used in HARPY","p":["HARPY is the sum of its parts, and out of tremendous respect for the developers involved in the included software, we would like to highlight the tools directly involved in HARPY's many moving pieces."]}]]